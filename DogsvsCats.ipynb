{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dogs vs. Cats\n",
    "This is my first Kaggle competition and also my first deep learning project from scratch.  \n",
    "This notebook is for implementing training and testing process using pytorch.\n",
    "![spring](https://kaggle2.blob.core.windows.net/competitions/kaggle/3362/media/woof_meow.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data\n",
    "### 1.  Data loading and transforming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms, models, datasets \n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "modes = ['train', 'val']\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224,scale=(0.08,1.0)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ])    \n",
    "}\n",
    "\n",
    "dogcat_datasets = {mode: datasets.ImageFolder(mode, data_transforms[mode]) for mode in modes}\n",
    "dogcat_dataloader = {mode: DataLoader(dogcat_datasets[mode], batch_size=batch_size,\n",
    "                                      shuffle=True, num_workers=0)\n",
    "                     for mode in modes}\n",
    "\n",
    "class_names = dogcat_datasets['train'].classes\n",
    "num_classes = len(class_names)\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Visualizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_imgs(images, labels):\n",
    "    for i in range(len(images)):\n",
    "        image = images[i].numpy().transpose(1,2,0)\n",
    "        mean = [0.485, 0.456, 0.406]\n",
    "        std = [0.229, 0.224, 0.225]\n",
    "        image = np.clip(image*std+mean, 0, 1)\n",
    "        ax = plt.subplot(len(images)//8,8,i+1)\n",
    "        ax.set_title(class_names[labels[i]])\n",
    "        ax.axis('off')\n",
    "        plt.imshow(image)\n",
    "\n",
    "batch_1st = iter(dogcat_dataloader['train']).next()\n",
    "fig = plt.figure(figsize=(15,15))\n",
    "print(f'imgs batch size: {batch_1st[0].size()}, labels batch size: {batch_1st[1].size()}')\n",
    "print(f'Images in 1st batch of training set:')\n",
    "show_imgs(*batch_1st)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model and Training\n",
    "### 3. Loading model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import *\n",
    "\n",
    "# define a pretrained network Resnet-18\n",
    "resnet = models.resnet18(pretrained=True)\n",
    "model_res = Res(resnet, num_classes)\n",
    "# define a network similar to darknet-19\n",
    "model_dark = Darknet(num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Training and visualizing histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_and_test import *\n",
    "\n",
    "criterion_res = nn.CrossEntropyLoss()\n",
    "optimizer_res = optim.SGD(model_res.params, lr=0.01, momentum=0.9, weight_decay=0.0005)\n",
    "lr_pattern_res = optim.lr_scheduler.StepLR(optimizer_res, 10, gamma=0.1)\n",
    "tracker_res = Epoch_History()\n",
    "\n",
    "# 4a) transfer learning using Resnet, freeze all network except final layer\n",
    "# History_tl = train_model(model_res, dogcat_dataloader, criterion_res, optimizer_res, \n",
    "#             num_epochs=1,\n",
    "#             lr_pattern=lr_pattern_res, \n",
    "#             device=device, \n",
    "#             history_tracker=tracker_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a small subset of train and val set to test train_model() function\n",
    "from train_and_test import *\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "sub_dogcat = {mode: Subset(dogcat_datasets[mode], range(100)) for mode in modes}\n",
    "sub_dogcat_loader = {mode: DataLoader(sub_dogcat[mode], batch_size=10,\n",
    "                                      shuffle=True, num_workers=0)\n",
    "                     for mode in modes}\n",
    "\n",
    "sub_H = train_model(model_res, sub_dogcat_loader, criterion_res, optimizer_res, \n",
    "                    lr_pattern=lr_pattern_res, \n",
    "                    device=device, \n",
    "                    num_epochs=2, \n",
    "                    history_tracker=tracker_res)\n",
    "\n",
    "sub_H.plot_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4b) training a self-defined model from scratch, construct similar to darknet19\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing and post processing predictions\n",
    "### 5. Loading testset and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from test_dataset import *\n",
    "\n",
    "# 5a) testing data without fivecrop\n",
    "testset_nofivecrop = TestDataset(fivecrop=False, test_dir='./test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# try test_model() function using a subset of total testset\n",
    "from train_and_test import *\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "sub_nofive = Subset(testset_nofivecrop, range(50))\n",
    "sub_nofive_loader = DataLoader(sub_nofive)\n",
    "r_nofive = test_model(model_res, sub_nofive_loader, device=device)\n",
    "\n",
    "for r in r_nofive:\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5b) testing data with fivecrop\n",
    "testset_fivecrop = TestDataset(fivecrop=True, test_dir='./test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try test_model() function using a subset of total testset\n",
    "from train_and_test import *\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "sub_five = Subset(testset_fivecrop, range(50))\n",
    "sub_five_loader = DataLoader(sub_five)\n",
    "r_five = test_model(model_res, sub_five_loader, fivecrop=True, device=device)\n",
    "\n",
    "for r in r_five:\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_res.load_state_dict(torch.load('./weights_res.pt', map_location='cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Test finished, submission csv saved!\n",
      "Images tested:    100\n",
      "Total time:       23.672s\n",
      "Time per image:   0.237s\n"
     ]
    }
   ],
   "source": [
    "from train_and_test_probability import *\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "sub_nofive = Subset(testset_nofivecrop, range(100))\n",
    "sub_nofive_loader = DataLoader(sub_nofive)\n",
    "r_nofive = test_model(model_res, sub_nofive_loader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00002942 100\n"
     ]
    }
   ],
   "source": [
    "from math import log\n",
    "def logloss(n, y):\n",
    "    if y==1:\n",
    "        return -y*log(n)\n",
    "    else:\n",
    "        return -(1-y)*log(1-n)\n",
    "\n",
    "loss = 0.0\n",
    "for i, r in enumerate(r_nofive):\n",
    "    if r[1]>0.5:\n",
    "        y=1\n",
    "    else:\n",
    "        y=0\n",
    "#     print(logloss(r[1], y))\n",
    "    loss += logloss(r[1], y)\n",
    "    loss /= (1+i)\n",
    "print(f'{loss*12500/(i+1):.8f}', 1+i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
